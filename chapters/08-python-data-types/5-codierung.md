# Codierung 

In diesem Kapitel haben wir nun eine Reihe von Datentypen kennengelernt: ``int``, ``bool``, ``float`` aber auch zusammengesetzte Datentypen wie ``str`` (Zeichenkette) oder eine Liste von Strings.

Im Kapitel √ºber [Codierung](sec-codierung) haben wir bereits gesehen, dass alle Informationen im Computer als Bitfolgen gespeichert werden und dass eine **Codierung** festlegt, wie diese Bitfolgen zu interpretieren sind.

Wie also werden die Datentypen, die wir in diesem Kapitel kennengelernt haben, abgespeichert?

## Codierung vs. Zahlensysteme

Bevor wir uns den verschiedenen Codierungsverfahren widmen, ist es wichtig, den Unterschied zwischen **Codierung** und **Zahlensystemen** zu verstehen:

```{admonition} Codierung
:name: def-encoding
:class: definition
Eine **Codierung** (engl. *encoding*) legt fest, wie eine Bitfolge zu interpretieren ist.
Sie definiert eine Zuordnung zwischen Bitfolgen und deren Bedeutung.
```

```{admonition} Zahlensystem
:name: def-number-system
:class: definition
Ein **Zahlensystem** ist eine Darstellungsweise von Zahlen.
Es legt fest, wie Zahlen mit Ziffern notiert werden (z.B. Dezimal, Bin√§r, Hexadezimal).
```

**Wichtiger Unterschied:**
- Ein **Zahlensystem** ist nur eine **Notation** oder **Darstellung** von Zahlen. Die Zahl $13_{10}$ kann als $1101_2$ (bin√§r) oder als $D_{16}$ (hexadezimal) geschrieben werden - es ist dieselbe Zahl, nur anders dargestellt.
- Eine **Codierung** legt fest, wie eine **Bitfolge** interpretiert wird. Die Bitfolge `01000001` kann je nach Codierung unterschiedliche Bedeutungen haben:
  - Als Zahl: $65_{10}$ (wenn wir die Bitfolge als Bin√§rzahl interpretieren)
  - Als Buchstabe: "A" (wenn wir die Bitfolge als ASCII-Zeichen interpretieren)

F√ºr Details zur Umrechnung zwischen verschiedenen Zahlensystemen siehe das Kapitel [Zahlensysteme](sec-number-systems).

## Zahlen

F√ºr Zahlen gibt es verschiedene Codierungsverfahren, die je nach Art der Zahl unterschiedlich sind.

### Ganze Zahlen (nat√ºrliche Zahlen)

Ganze Zahlen wie z.B. die dezimale $13_{10}$ lassen sich als Bitfolge darstellen, indem wir die Zahl in das Bin√§rsystem umrechnen.
In diesem einfachen Fall nutzen wir das Bin√§rsystem als **Zahlensystem** - wir stellen die Zahl $13_{10}$ als $1101_2$ dar.

Eine Bin√§rzahl $b_{n-1} \ldots b_0$ mit $b_i \in \{0,1\}$ hat den Wert

$$b_{n-1} \cdot 2^{n-1} + \ldots + b_0 \cdot 2^0 = \sum\limits_{i=0}^{n-1} b_i \cdot 2^i.$$

Zum Beispiel hat $1101_2$ den Wert

$$1 \cdot 2^3 + 1 \cdot 2^2 + 0 \cdot 2^1 + 1 \cdot 2^0 = 8 + 4 + 0 + 1 = 13_{10}.$$

Hierbei handelt es sich um einen direkten **Zahlensystemwechsel** - keine spezielle Codierung im eigentlichen Sinne.
Die **Codierung** besteht lediglich darin, dass wir festlegen: "Diese Bitfolge wird als Bin√§rzahl interpretiert."

F√ºr Details zur Umrechnung zwischen Dezimal- und Bin√§rsystem siehe das Kapitel [Zahlensysteme](sec-number-systems).

### Negative Zahlen (Zweierkomplement)

F√ºr die Darstellung von **negativen ganzen Zahlen** wird in Computern das **Zweierkomplement** verwendet.
Hierbei handelt es sich um eine **Codierung**, die festlegt, wie Bitfolgen als negative Zahlen interpretiert werden.

Das h√∂chste Bit wird dabei nicht als einfaches Vorzeichenbit, sondern als negativer Anteil interpretiert.

Im *Zweierkomplement* wird eine Zahl $b_{n-1} \ldots b_0$ wie folgt interpretiert:

```{math}
:label: eq:binary:integer
  b_{n-1} \ldots b_0 = -b_{n-1} \cdot 2^{n-1} + \sum\limits_{i=0}^{n-2} b_i \cdot 2^i.
```

**Beispiel f√ºr 8-Bit-Zahlen:**
- $0$-$127$: positive Zahlen (h√∂chstes Bit = 0)
- $128$-$255$: negative Zahlen im Zweierkomplement (h√∂chstes Bit = 1)

So kann mit 8 Bits der Bereich von $-128$ bis $+127$ dargestellt werden.

**Beispiele:**
- $1011_2$ (4 Bits) = $-2^3 \cdot 1 + 2^2 \cdot 0 + 2^1 \cdot 1 + 2^0 \cdot 1 = -8 + 2 + 1 = -5_{10}$
- $111_2$ (3 Bits) = $-2^2 \cdot 1 + 2^1 \cdot 1 + 2^0 \cdot 1 = -4 + 2 + 1 = -1_{10}$

```{admonition} Hinweis: Zweierkomplement
:class: note

Das Zweierkomplement ist eine **Codierung**, die festlegt, wie Bitfolgen als negative Zahlen interpretiert werden.
Es ist mehr als nur ein Zahlensystem - es definiert eine spezielle Interpretation von Bitfolgen f√ºr negative Werte.

F√ºr detaillierte Informationen √ºber das Zweierkomplement, die Umrechnung zwischen positiven und negativen Zahlen sowie Addition und Subtraktion im Bin√§rsystem siehe das Kapitel [Zahlensysteme](sec-number-systems).
```

### Gleitkommazahlen (IEEE 754)

F√ºr Zahlen mit Nachkommastellen (z.B. $3.14$ oder $0.0000000001$) reicht ein einfacher Zahlensystemwechsel nicht aus. Hier ist eine spezielle **numerische Codierung** erforderlich, die festlegt, wie das Komma, die Nachkommastellen und Rundungen repr√§sentiert werden.

Der Standard f√ºr die Codierung von Gleitkommazahlen ist **IEEE 754** (Institute of Electrical and Electronics Engineers Standard 754). Dieser Standard legt fest, wie Flie√ükommazahlen im Computer gespeichert werden.

Gleitkommazahlen werden nach dem IEEE 754-Standard codiert, indem die Zahl in drei Komponenten aufgeteilt wird:

1. **Vorzeichenbit**: Bestimmt, ob die Zahl positiv (0) oder negativ (1) ist
2. **Exponent**: Bestimmt die Gr√∂√üenordnung der Zahl (wo das Komma steht)
3. **Mantisse** (auch Signifikand): Enth√§lt die signifikanten Ziffern der Zahl

Die Idee ist √§hnlich der wissenschaftlichen Schreibweise: Eine Zahl wie $1234.56$ kann als $1.23456 \times 10^3$ geschrieben werden. Im Bin√§rsystem funktioniert dies analog mit Potenzen von 2.

In Python werden Flie√ükommazahlen (``float``) nach dem IEEE 754-Standard mit **64 Bits** (8 Bytes) gespeichert:

- **1 Bit** f√ºr das Vorzeichen
- **11 Bits** f√ºr den Exponenten
- **52 Bits** f√ºr die Mantisse

Diese Aufteilung erm√∂glicht es, sowohl sehr kleine Zahlen (z.B. $0.0000000001$) als auch sehr gro√üe Zahlen (z.B. $10000000.0$) mit der gleichen Anzahl von Bits darzustellen, indem die Position des "Kommas" (genauer: des Bin√§rpunkts) durch den Exponenten verschoben wird.

```{admonition} Wichtig 
:class: important

**Rundungsfehler**: Aufgrund der begrenzten Anzahl von Bits k√∂nnen nicht alle Dezimalzahlen exakt als Gleitkommazahlen dargestellt werden. Dies f√ºhrt zu Rundungsfehlern, die bei Berechnungen auftreten k√∂nnen.

**Beispiel:**
```python
0.1 + 0.2 == 0.3  # False!
```

Dies liegt daran, dass $0.1$ im Bin√§rsystem eine periodische Zahl ist und nicht exakt dargestellt werden kann. F√ºr die meisten praktischen Anwendungen sind diese Rundungsfehler jedoch vernachl√§ssigbar klein.

**Genauigkeit**: Mit 64 Bits k√∂nnen etwa 15-17 signifikante Dezimalstellen dargestellt werden. F√ºr die meisten technischen Berechnungen ist dies ausreichend.
```

## Text

Text besteht aus Zeichen (Buchstaben, Ziffern, Sonderzeichen), die als Bitfolgen codiert werden m√ºssen. Hierbei handelt es sich um eine **Codierung** im eigentlichen Sinne: Wir legen fest, welche Bitfolge welchem Zeichen entspricht.

Wie wir bereits im Kapitel √ºber [Codierung](sec-codierung) gesehen haben, kann die gleiche Bitfolge `01000001` je nach Codierung unterschiedliche Bedeutungen haben:
- Als Zahl: $65_{10}$ (wenn wir die Bitfolge als Bin√§rzahl interpretieren)
- Als Buchstabe: "A" (wenn wir die Bitfolge als ASCII-Zeichen interpretieren)

### Grundprinzip der Zeichencodierung

Wollen wir die Buchstaben des Alphabets in Bin√§rdarstellung schreiben, so m√ºssen wir uns darauf einigen, welche Bin√§rzahl welchen Buchstaben repr√§sentiert.
Dies ist eine **Codierung** - wir legen fest, wie Bitfolgen als Zeichen interpretiert werden.

Da das lateinische Alphabet 26 Gro√übuchstaben enth√§lt, brauchen wir mindestens 5 Bits, denn es gilt:

$$2^4 < 26 \leq 2^5.$$

Mit 5 Bits k√∂nnen wir $2^5 = 32$ verschiedene Zeichen darstellen, was f√ºr die 26 Buchstaben ausreicht.

```{exercise} Repr√§sentation
:label: repraesentation-alphabet-exercise
Wie viele Bits ben√∂tigen Sie, wenn Sie die Kleinbuchstaben auch repr√§sentieren m√∂chten?
```

```{solution} repraesentation-alphabet-exercise
:label: repraesentation-alphabet-solution
:class: dropdown
Mit Kleinbuchstaben haben wir $52$ Elemente und brauchen somit $6$ Bits, denn 

$$2^5 < 52 \leq 2^6$$
```

Ein Wort besteht nat√ºrlich aus mehreren Buchstaben.
Zum Beispiel w√§re *BAD* repr√§sentiert durch die Konkatenation der Bin√§rdarstellungen der einzelnen Buchstaben.
Im Computer w√ºrden demnach mehrere Bits, die entweder den Zustand **Strom aus** oder **Strom an** haben, das Wort repr√§sentieren.

Sonderzeichen wie Leerzeichen oder weitere Zeichen m√ºssten wir in unsere Codierung noch einf√ºgen.
Auch k√∂nnten wir einen vollkommen anderen Zeichensatz benutzen.
Programme, die auf diesem aufbauen, m√ºssen die Codierung lediglich kennen.

Auch k√∂nnen wir l√§ngere W√∂rter oder ganze S√§tze bilden, brauchen daf√ºr nat√ºrlich Speicherplatz.
In unserem Beispiel ben√∂tigt jeder Buchstabe 5 Bits.
D. h., um einen Text mit, sagen wir 300 Zeichen im Speicher zu halten, brauchen wir die Bauteile f√ºr mindestens $300 \times 5 = 1500$ Bits, was wiederum $187.5$ Bytes bzw. $0.1875$ [kiloByte](https://en.wikipedia.org/wiki/Kilobyte) (kB) ($10^3$ Byte) und ca. $0.1831$ [kibiByte](https://en.wikipedia.org/wiki/Kilobyte) (KB/KiB) ($2^{10}$ Byte) sind.

### ASCII

Eine der ersten wichtigen Zeichencodierungen ist **ASCII** (American Standard Code for Information Interchange). ASCII verwendet 7 Bits und kann damit 128 verschiedene Zeichen darstellen (0-127).

ASCII ist eine **Codierung**, die festlegt:
- Welche Bitfolge welchem Zeichen entspricht
- Wie Zeichen als Bitfolgen gespeichert werden

ASCII enth√§lt:
- Lateinische Gro√ü- und Kleinbuchstaben (A-Z, a-z)
- Ziffern (0-9)
- Sonderzeichen und Satzzeichen (!, ?, ., etc.)
- Steuerzeichen (z.B. Zeilenumbruch, Tabulator)

**Beispiel:**
- Der Buchstabe "A" hat den ASCII-Code $65_{10}$, was der Bitfolge `01000001` entspricht
- Der Buchstabe "a" hat den ASCII-Code $97_{10}$

ASCII hat jedoch eine wichtige Limitation: Es kann nur englische Zeichen darstellen. Umlaute (√§, √∂, √º), Akzente (√©, √®, √†) oder Zeichen aus anderen Schriftsystemen (z.B. Chinesisch, Arabisch) sind nicht enthalten. Auch Emojis k√∂nnen nicht dargestellt werden.

### Unicode

Um diese Einschr√§nkung zu √ºberwinden, wurde **Unicode** entwickelt ‚Äì ein universeller Zeichensatz, der Zeichen aus praktisch allen Sprachen und Schriftsystemen der Welt umfasst. Unicode definiert f√ºr jedes Zeichen eine eindeutige Nummer, den sogenannten **Code Point**.

Unicode enth√§lt weit mehr Zeichen als ASCII:
- Alle ASCII-Zeichen (Code Points 0-127)
- Umlaute und Akzente (√§, √∂, √º, √©, √®, √†, etc.)
- Zeichen aus anderen Schriftsystemen (Chinesisch, Arabisch, Kyrillisch, etc.)
- Emojis und Sonderzeichen (üéâ, ‚Ç¨, ¬©, etc.)

Wichtig: Unicode definiert nur, *welche* Zeichen es gibt und welche Nummer (Code Point) jedes Zeichen hat. Es legt jedoch **nicht** fest, wie diese Zeichen als Bitfolgen gespeichert werden sollen. Unicode ist also noch keine vollst√§ndige Codierung - es ist eine Zuordnung von Zeichen zu Nummern.

### UTF-8

**UTF-8** (Unicode Transformation Format 8-bit) ist eine **Codierung**, die festlegt, wie Unicode-Zeichen als Bitfolgen gespeichert werden. UTF-8 ist die Standard-Codierung f√ºr Python-Strings.

UTF-8 verwendet eine **variable L√§nge**: Je nach Zeichen werden unterschiedlich viele Bytes verwendet:

- **1 Byte** f√ºr ASCII-Zeichen (z.B. "A", "1", "!")
- **2 Bytes** f√ºr viele europ√§ische Zeichen (z.B. "√§", "√∂", "√º", "√©")
- **3 Bytes** f√ºr viele andere Zeichen (z.B. "‚Ç¨", "¬©")
- **4 Bytes** f√ºr Emojis und einige seltene Zeichen (z.B. "üéâ", "üöÄ")

**Beispiele:**
- "A" ‚Üí 1 Byte (gleich wie ASCII)
- "√§" ‚Üí 2 Bytes
- "‚Ç¨" ‚Üí 3 Bytes
- "üéâ" ‚Üí 4 Bytes

Ein wichtiger Vorteil von UTF-8 ist die **R√ºckw√§rtskompatibilit√§t zu ASCII**: Alle ASCII-Zeichen werden in UTF-8 genauso codiert wie in ASCII. Das bedeutet, dass jeder ASCII-Text automatisch auch ein g√ºltiger UTF-8-Text ist.

```{admonition} Wichtig
:class: important

**Python Strings sind UTF-8**: In Python werden Strings standardm√§√üig als UTF-8 gespeichert. Sie k√∂nnen mit den Funktionen ``ord()`` und ``chr()`` zwischen Zeichen und ihren Unicode-Code Points umwandeln:

```python
ord('A')    # 65
chr(65)     # 'A'
ord('√§')    # 228
chr(228)    # '√§'
ord('üéâ')   # 127881
```

**Encoding-Probleme**: Bei der Arbeit mit Dateien oder beim Datenaustausch √ºber Netzwerke kann es zu Encoding-Problemen kommen, wenn die Codierung nicht korrekt angegeben wird. Stellen Sie sicher, dass Sie beim √ñffnen von Dateien das richtige Encoding angeben (z.B. ``open('datei.txt', encoding='utf-8')``).
```
